{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 2: Naive Bayes classification\n",
    "\n",
    "Answer each question. You may discuss answers with other students, but write your own solution. Some questions have more than one part. Most questions involve coding, some require you to comment.\n",
    "\n",
    "Can you tell whether a review of a restaurant is positive or negative? What words are most indicative? We'll examine data from Yelp, provided as part of the Yelp Academic Challenge.\n",
    "\n",
    "To do this, we will create a program (a classifier) that uses actual examples of one-star and five-star reviews to classify a new review as positive or negative.  This classifier will estimate the probability that a review is negative or positive based on the words in that review and assign the most likely label (negative or positive).\n",
    "\n",
    "Some terminology: the word \"word\" can mean two different things, so we will be more specific. The phrase \"red fish blue fish\" contains a sequence of four word *tokens*, but only three distinct word *types* (red, fish, blue). \n",
    "\n",
    "### Q1: guesses before looking at data\n",
    "\n",
    "Before we start coding, list five word types that you think stongly indicate a positive review and five that indicate a negative review:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive words here: Nice, Great, Aesome, Good, Positive, happy, satisfied\n",
    "Negative words here: Gross, Discussting, Bad, Unhappy, Unstatisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a program that uses actual examples of one-star and five-star reviews to classify text as positive and negative.\n",
    "\n",
    "We start by partioning our collection of pre-labeled restaurant reviews into two sets, positive reviews and negative reviews. (We have done this for you.) We will then count the relative frequency of each distinct word type in the two sub-collections which will allow us to estimate the probability that a given word appears in a review given its polarity (positive or negative). These individual word probabilites will then be multiplied to etimate the probability of multiple word tokens appearing in a document given its polarity. Finally, we can then appply Bayes theorem to switch our conditionals: i.e. to estimate the probability a review is positive or negative based on the words in it.\n",
    "\n",
    "Here's the math. The first line is an application of Bayes' rule. The second line expands the marginal probability of the words into the sum over positive and negative polarities. The third line adds the \"naive\" assumption that words are independent, as long as we know the polarity. (Note that I flipped the order of the prior probability and the word probability in the third line, to make it clear where the product ends.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Can you write psedocode that describes a high level what we're trying to do?\n",
    "##Be sure to differentiate in your pseudocode between training and testing.\n",
    "##In particular, how we are estimating the above probabilities in training\n",
    "##and how are they used in classfication (testing)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pseduocode (not exact algorithm)\n",
    "\n",
    "##input: a training set of labelled documents, a testing set of unlabelled documents\n",
    "\n",
    "##'training'\n",
    "\n",
    "## Step1: partition training set by label\n",
    "## Step 2: for each label compute p(label) = probability of that label =\n",
    "##        (# of documents with the given label) / total number of documents## \n",
    "## Step3: for each label:\n",
    "# for each document in taht label class:\n",
    "#     maintain count of word appearing in each doc\n",
    "#     compute probability of each word appearing in given label = ?\n",
    "    \n",
    "##    for reach testing doc, compute prob of label given words in doc using bayes thm\n",
    "##    naive babyes assumption and estimates for prob computed above\n",
    "##    assign most likely label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint for later:\n",
    "#     when we classsify, we will assign most likely label (+ or -)\n",
    "#     notice that we can then just check wheter p(+ | words) / p( - | words)is bigger thant or smaller than 1\n",
    "#     why is this particularly convenient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P(positive|w_1, w_2, w_3, ..., w_N) & = \\frac{P(w_1, w_2, w_3, ..., w_N | positive)P(positive)}{P(w_1, w_2, w_3, ..., w_N)} \\\\\n",
    "&= \\frac{P(w_1, w_2, w_3, ..., w_N | positive)P(positive)}{P(w_1, w_2, w_3, ..., w_N | positive)P(positive) + P(w_1, w_2, w_3, ..., w_N | negative)P(negative)} \\\\\n",
    "&\\approx \\frac{P(positive)\\prod_i P(w_i|positive)}{P(positive)\\prod_i P(w_i|positive) + P(negative)\\prod_i P(w_i|negative) }\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: create a pattern\n",
    "\n",
    "The first step is to count the words in each of the two *training* sub-collections. They are in two files, `positive.txt` and `negative.txt`. Each line in these files is one review. Before we start, we need to decide how we are going to break reviews into words.\n",
    "\n",
    "Create a regular expression that matches sequences of one or more letter characters. Then write a short sentence and use the `findall` function to list all of the substrings of that sentence that match your pattern. Include at least one common word in your sentence that will not be handled well by this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Hint: import re, a regular expression module\n",
    "## re.compile(my_reg_exp) will create a 'regular expression object' defined by my_reg_exp\n",
    "##regular expression objects have a member function .findall(string) that will return all\n",
    "##substrings in string matching the regular expression object\n",
    "\n",
    "##Whats wrong with this?\n",
    "##Why can't we use split: because it also picks up isolated punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'class', 'rocks']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "my_reg_exp=re.compile(\"\\w+\")\n",
    "my_reg_exp.findall(\"This class rocks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can', 't', 'not', 'won', 't']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Can', 't', 'not', 'won', 't']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Specify variables to store data\n",
    "\n",
    "To apply Bayes' rule to estimate the probability of polarity given a review, we need the probability of words given polarity and the probability of positive or negative polarity.\n",
    "\n",
    "First create variables that will store this information.\n",
    "For the positive reviews create a `Counter` that will store the counts of words in positive reviews. Also create a variable that will count the number of positive reviews. Create similar variables for the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pos_word_counts = Counter()\n",
    "neg_word_counts = Counter()\n",
    "num_pos_reviews = 0\n",
    "num_neg_reviews = 0\n",
    "\n",
    "##Counter has a function .update list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_document_counts = Counter()\n",
    "pos_document_counts = 0\n",
    "neg_document_counts = Counter()\n",
    "neg_document_counts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Read data from files\n",
    "\n",
    "Now read the two files, collecting the count of each distinct word in each sub-collection, as well as the number of reviews in each sub-collection. You will need to *update* the appropriate `Counter` for each review.\n",
    "\n",
    "Once you have processed the two files, test the counters by printing the five most common words in each counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7766\n",
      "1580\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "##re.compile(my_reg_exp) will create a regular expression object define by my_reg_exp. \n",
    "##.findall(string) will return all substrings in string matching the regular expression object\n",
    "with open(\"positive.txt\", \"r\") as pos_reader:\n",
    "    try:\n",
    "        for review in pos_reader:\n",
    "            ##my_reg_exp = re.compile('[a-z]+')\n",
    "            ##q = my_reg_exp.findall(line)\n",
    "            ##print (q)\n",
    "            pos_word_counts.update(my_reg_exp.findall(review))\n",
    "            num_pos_reviews += 1\n",
    "    except UnicodeDecodeError:\n",
    "        pass    \n",
    "with open(\"negative.txt\", \"r\") as neg_reader:\n",
    "    try:\n",
    "        for review in neg_reader:\n",
    "            ##my_reg_exp = re.compile('[a-z]+')\n",
    "            ##q = my_reg_exp.findall(line)\n",
    "            ##print (q)\n",
    "            neg_word_counts.update(my_reg_exp.findall(review))\n",
    "            num_neg_reviews += 1\n",
    "    except UnicodeDecodeError:\n",
    "        pass           \n",
    "print(num_pos_reviews)\n",
    "print(num_neg_reviews)\n",
    "\n",
    "temp_list = []\n",
    "for key in pos_word_counts:\n",
    "    temp_list.append(pos_word_counts[key])\n",
    "\n",
    "        \n",
    "##print(\"positive reviews:\" + str(pos_word_counts))\n",
    "##print(\"negative reviews:\" + str(neg_word_counts))\n",
    "\n",
    "##PRINT MOST COMMON WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open(\"negative.txt\",'r') as neg_reader:\n",
    "    try:\n",
    "        for line in neg_reader:\n",
    "            neg_word_counts.update(my_reg_exp.findall(line))\n",
    "            num_neg_reviews +=1\n",
    "    except UnicodeDecodeError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "#     for document in documents\n",
    "#     neg_word_counts.update()\n",
    "#     neg_document_counts +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: prior probability\n",
    "\n",
    "Calculate the probability that a randomly selected review is positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3088363954505687\n",
      "0.6911636045494314\n"
     ]
    }
   ],
   "source": [
    "pos_prob = num_pos_reviews/(num_pos_reviews + num_neg_reviews) # Number of docs that are positive\n",
    "neg_prob = num_neg_reviews/(num_pos_reviews + num_neg_reviews) # Number of docs that are negative\n",
    "print(pos_prob)\n",
    "print(neg_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this value surprise you? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: count word totals\n",
    "\n",
    "Create two variables, `positive_tokens` and `negative_tokens`, whose value is the total number of word tokens in that sub-collection. Print these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415765\n",
      "126358\n"
     ]
    }
   ],
   "source": [
    "\n",
    "positive_tokens = 0\n",
    "for key in pos_word_counts:\n",
    "    positive_tokens = positive_tokens + pos_word_counts[key]\n",
    "print(positive_tokens)\n",
    "\n",
    "negative_tokens = 0\n",
    "for key in neg_word_counts:\n",
    "    negative_tokens = negative_tokens + neg_word_counts[key]\n",
    "print(negative_tokens)\n",
    "\n",
    "##positive_tokens = sum(pos_word_counts.values())\n",
    "##negative_tokens = sum(neg_word_counts.values())\n",
    "\n",
    "##print(positive_tokens)\n",
    "##print(negative_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: calculate word probability (version 1.0)\n",
    "\n",
    "Create a function `word_prob` that takes three arguments: a word, a counter, and a sum. It should return the probability of the word estimated from that counter. Assume that the sum is accurate, you don't need to check for errors.\n",
    "\n",
    "Use this function to print the probability of the words \"delicious\", \"manager\", \"edgy\", and \"vile\" in both sub-collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "sum = 0\n",
    "def word_prob(word, counter, sum):\n",
    "    prob = \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive\n",
    "print(word_prob(\"delicious\", counter, sum))\n",
    "print(word_prob(\"manager\", counter, sum))\n",
    "print(word_prob(\"edgy\", counter, sum))\n",
    "print(word_prob(\"vile\", counter, sum))\n",
    "\n",
    "#Negative\n",
    "print(word_prob(\"delicious\", counter, sum))\n",
    "print(word_prob(\"manager\", counter, sum))\n",
    "print(word_prob(\"edgy\", counter, sum))\n",
    "print(word_prob(\"vile\", counter, sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: probability of a sequence (version 1.0)\n",
    "\n",
    "Now create a function `review_prob` that takes a string containing multiple words (for example \"the food was delicious\"), a counter, and a sum. It should use the same regular expression method you used when reading the files earlier to break this string into tokens, and then use `word_prob` to calculate the probability of each of those word tokens. It should then return the product of those probabilities.\n",
    "\n",
    "Print the probability of \"I loved the carnitas\", \"but then the manager came out and told us\", and \"the ambience was edgy but the food was vile\" according to both sub-collections. What do you notice about these six probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_prob(phrase, counter, sum):\n",
    "    word_prob\n",
    "    probproduct =\n",
    "    return probproduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_prob(\"I loved the carnitas\", counter, sum))\n",
    "print(review_prob(\"but then the manager came out and told us\", counter, sum)\n",
    "print(review_prob(\"the ambience was edgy but the food was vile\", counter, sum)\n",
    "\n",
    "print(review_prob(\"I loved the carnitas\", counter, sum))\n",
    "print(review_prob(\"but then the manager came out and told us\", counter, sum)\n",
    "print(review_prob(\"the ambience was edgy but the food was vile\", counter, sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I notice that these probabilities are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations about the six probabilities here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: calculate word probability (version 2.0)\n",
    "\n",
    "Instead of multiplying probabilities, we can also add *log* probabilities. Create a function `word_log_prob` that calculates the log probability of a word, and a function `review_log_prob` that calculates the sum of the log probabilities of the words in a string. These should take the same arguments as the previous functions.\n",
    "\n",
    "Print the log probabilities of the same example words and sentences from the previous problems. Explain any errors that occur in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculates log probability of a word\n",
    "def word_log_prob(word, counter, sum):\n",
    "    logProb =\n",
    "    return logProb\n",
    "\n",
    "## Calculates sum of log probabilities of words in a string\n",
    "def review_log_prob(phrase, counter, sum):\n",
    "    logProbString =\n",
    "    return logProbString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive\n",
    "print(word_log_prob(\"delicious\", counter, sum))\n",
    "print(word_log_prob(\"manager\", counter, sum))\n",
    "print(word_log_prob(\"edgy\", counter, sum))\n",
    "print(word_log_prob(\"vile\", counter, sum))\n",
    "\n",
    "#Negative\n",
    "print(word_log_prob(\"delicious\", counter, sum))\n",
    "print(word_log_prob(\"manager\", counter, sum))\n",
    "print(word_log_prob(\"edgy\", counter, sum))\n",
    "print(word_log_prob(\"vile\", counter, sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_log_prob(\"I loved the carnitas\", counter, sum))\n",
    "print(review_log_prob(\"but then the manager came out and told us\", counter, sum)\n",
    "print(review_log_prob(\"the ambience was edgy but the food was vile\", counter, sum)\n",
    "\n",
    "print(review_log_prob(\"I loved the carnitas\", counter, sum))\n",
    "print(review_log_prob(\"but then the manager came out and told us\", counter, sum)\n",
    "print(review_log_prob(\"the ambience was edgy but the food was vile\", counter, sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a word type never occurs in our negative reviews, it will have probability zero. But we don't want to rule out the possibility that any future negative review could include that word type. We need to a way to give non-zero probability in both positive and negative polarities to a word that we have only seen in one. A simple way to do this is to add 1 to the count when we calculate word probability, as long as the word has appeared in at least one sub-collection (words we have never seen in either sub-collection will still have probability zero).\n",
    "\n",
    "This change avoids log-zero errors, but it violates the laws of probability. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Collection statistics\n",
    "\n",
    "Create a `Counter` called `both_counts` by adding the two negative and positive counters together (just use +, Counters are awesome). Create a new variable `both_tokens` to represent the total number of tokens in the collection. Create a variable `vocabulary_size` whose value is the total number of distinct word types in the collection. Print the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_counts = PosCounter + NegCounter #use Counter variables already created\n",
    "both_tokens = ## total number of tokens in collection \n",
    "vocabulary_size = ##total number of distinct word types in the collection\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11: Calculate word probability (version 3.0)\n",
    "\n",
    "Now create a function `smoothed_word_log_prob` that takes the same arguments as `word_prob` (word, counter, sum of the counter), but adds 1 to the count for the word (don't modify the counter, just add 1 in your function). Previously we divided the word count by the sum of all the counts in the counter, which guaranteed that the sum of the probability of all word types was 1.0. Now that we are adding 1 to each word, what should the denominator be so that this new probability distribution will sum to 1.0?\n",
    "\n",
    "Use this function to print the log probability of the words \"delicious\", \"manager\", \"edgy\", and \"vile\" in both sub-collections. (These function calls should have the exact same arguments as the previous blocks.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smoothed_word_log_prob(word, counter, sum):\n",
    "    counter = counter + 1\n",
    "    logProb = \n",
    "    return logProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive\n",
    "print(word_log_prob(\"delicious\", counter, sum))\n",
    "print(word_log_prob(\"manager\", counter, sum))\n",
    "print(word_log_prob(\"edgy\", counter, sum))\n",
    "print(word_log_prob(\"vile\", counter, sum))\n",
    "\n",
    "#Negative\n",
    "print(word_log_prob(\"delicious\", counter, sum))\n",
    "print(word_log_prob(\"manager\", counter, sum))\n",
    "print(word_log_prob(\"edgy\", counter, sum))\n",
    "print(word_log_prob(\"vile\", counter, sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12: Test your classifier!\n",
    "\n",
    "Now let's put it all together. Given a review, we want to know whether that review is more likely to be positive or negative. To answer this question we will calculate the log of the ratio between $P(positive | words\\ in\\ review)$ and $P(negative | words\\ in\\ review)$. This ratio is simpler than the two individual. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate this ratio for the review \"the ambience was edgy but the food was disgusting\". Use the probability that a review is positive or negative that you calculated earlier as the prior probabilities $P(positive)$ and $P(negative)$, but this time use the log of those probabilities. Print the resulting log probability ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How should you interpret the log probability ratio?\n",
    "* Which category is more likely?\n",
    "* Does the prior probability matter?\n",
    "* Suggest a prior probability that would change our decision, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
