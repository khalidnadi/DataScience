{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 2: Naive Bayes classification\n",
    "\n",
    "Answer each question. You may discuss answers with other students, but write your own solution. Some questions have more than one part. Most questions involve coding, some require you to comment.\n",
    "\n",
    "Can you tell whether a review of a restaurant is positive or negative? What words are most indicative? We'll examine data from Yelp, provided as part of the Yelp Academic Challenge.\n",
    "\n",
    "To do this, we will create a program (a classifier) that uses actual examples of one-star and five-star reviews to classify a new review as positive or negative.  This classifier will estimate the probability that a review is negative or positive based on the words in that review and assign the most likely label (negative or positive).\n",
    "\n",
    "Some terminology: the word \"word\" can mean two different things, so we will be more specific. The phrase \"red fish blue fish\" contains a sequence of four word *tokens*, but only three distinct word *types* (red, fish, blue). \n",
    "\n",
    "### Q1: guesses before looking at data\n",
    "\n",
    "Before we start coding, list five word types that you think stongly indicate a positive review and five that indicate a negative review:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive words here: \n",
    "Negative words here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a program that uses actual examples of one-star and five-star reviews to classify text as positive and negative.\n",
    "\n",
    "We start by partioning our collection of pre-labeled restaurant reviews into two sets, positive reviews and negative reviews. (We have done this for you.) We will then count the relative frequency of each distinct word type in the two sub-collections which will allow us to estimate the probability that a given word appears in a review given its polarity (positive or negative). These individual word probabilites will then be multiplied to etimate the probability of multiple word tokens appearing in a document given its polarity. Finally, we can then appply Bayes theorem to switch our conditionals: i.e. to estimate the probability a review is positive or negative based on the words in it.\n",
    "\n",
    "Here's the math. The first line is an application of Bayes' rule. The second line expands the marginal probability of the words into the sum over positive and negative polarities. The third line adds the \"naive\" assumption that words are independent, as long as we know the polarity. (Note that I flipped the order of the prior probability and the word probability in the third line, to make it clear where the product ends.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P(positive|w_1, w_2, w_3, ..., w_N) & = \\frac{P(w_1, w_2, w_3, ..., w_N | positive)P(positive)}{P(w_1, w_2, w_3, ..., w_N)} \\\\\n",
    "&= \\frac{P(w_1, w_2, w_3, ..., w_N | positive)P(positive)}{P(w_1, w_2, w_3, ..., w_N | positive)P(positive) + P(w_1, w_2, w_3, ..., w_N | negative)P(negative)} \\\\\n",
    "&\\approx \\frac{P(positive)\\prod_i P(w_i|positive)}{P(positive)\\prod_i P(w_i|positive) + P(negative)\\prod_i P(w_i|negative) }\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: create a pattern\n",
    "\n",
    "The first step is to count the words in each of the two *training* sub-collections. They are in two files, `positive.txt` and `negative.txt`. Each line in these files is one review. Before we start, we need to decide how we are going to break reviews into words.\n",
    "\n",
    "Create a regular expression that matches sequences of one or more letter characters. Then write a short sentence and use the `findall` function to list all of the substrings of that sentence that match your pattern. Include at least one common word in your sentence that will not be handled well by this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can', 't', 'do', 'this']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "my_reg_exp = re.compile(\"\\w+\")\n",
    "my_reg_exp.findall(\"Can't do this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Specify variables to store data\n",
    "\n",
    "To apply Bayes' rule to estimate the probability of polarity given a review, we need the probability of words given polarity and the probability of positive or negative polarity.\n",
    "\n",
    "First create variables that will store this information.\n",
    "For the positive reviews create a `Counter` that will store the counts of words in positive reviews. Also create a variable that will count the number of positive reviews. Create similar variables for the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pos_word_counts = Counter()\n",
    "neg_word_counts = Counter()\n",
    "num_pos_reviews = 0\n",
    "num_neg_reviews = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Read data from files\n",
    "\n",
    "Now read the two files, collecting the count of each distinct word in each sub-collection, as well as the number of reviews in each sub-collection. You will need to *update* the appropriate `Counter` for each review.\n",
    "\n",
    "Once you have processed the two files, test the counters by printing the five most common words in each counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n",
      "to\n",
      "a\n",
      "I\n",
      "and\n",
      "3883\n",
      "was\n",
      "a\n",
      "to\n",
      "and\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "\n",
    "with open(\"positive.txt\", 'r') as pos_reader:\n",
    "    my_reg_exp = re.compile(\"\\w+\")\n",
    "    for line in pos_reader:\n",
    "        ## update word counts in positive reviews\n",
    "        pos_word_counts.update(my_reg_exp.findall(line))\n",
    "        ## update our count for the number of positive reviews\n",
    "        num_pos_reviews += 1\n",
    "\n",
    "# print(pos_word_counts)\n",
    "pos_word_counts_dict = dict(pos_word_counts)\n",
    "# print(pos_word_counts_dict)\n",
    "sort = sorted(pos_word_counts_dict, key=pos_word_counts_dict.get)\n",
    "# print(sort)\n",
    "\n",
    "for i in range((len(sort)-6), (len(sort)-1)):\n",
    "    print(sort[i])\n",
    "    \n",
    "with open(\"negative.txt\", 'r') as neg_reader:\n",
    "    my_reg_exp = re.compile(\"\\w+\")\n",
    "    try:\n",
    "        for line in neg_reader:\n",
    "            neg_word_counts.update(my_reg_exp.findall(line))\n",
    "            num_neg_reviews += 1\n",
    "    except UnicodeDecodeError:\n",
    "        x=4\n",
    "print( num_pos_reviews)       \n",
    "neg_word_counts_dict = dict(neg_word_counts)\n",
    "sort2 = sorted(neg_word_counts_dict, key=neg_word_counts_dict.get)\n",
    "# print(sort2)\n",
    "\n",
    "for i in range(len(sort2)-6, len(sort2)-1):\n",
    "    print(sort2[i])\n",
    "        \n",
    "## for document in documents:\n",
    "## pos_word_counts.update()\n",
    "## pos_document_counts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (<ipython-input-5-53e2a34dd854>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-53e2a34dd854>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     read_a_file(\"file.txt\")\n",
    "# except UnicodeDecodeerror:\n",
    "#     continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: prior probability\n",
    "\n",
    "Calculate the probability that a randomly selected review is positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8309437192381768\n"
     ]
    }
   ],
   "source": [
    "# prob_pos = of positive reviews / (# of reviews)\n",
    "prob_pos = num_pos_reviews / (num_pos_reviews + num_neg_reviews)\n",
    "print(prob_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this value surprise you? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here: I think it's good that there are a good amount more positive reviews than negative reviews. I feel like in general people who are dissatisfied comment with bad reviews, while the satisfied people don't comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: count word totals\n",
    "\n",
    "Create two variables, `positive_tokens` and `negative_tokens`, whose value is the total number of word tokens in that sub-collection. Print these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415765\n",
      "126358\n"
     ]
    }
   ],
   "source": [
    "pos_tokens = 0\n",
    "for i in sort:\n",
    "    number = pos_word_counts_dict.get(i)\n",
    "    pos_tokens += number\n",
    "    \n",
    "print(pos_tokens)\n",
    "\n",
    "neg_tokens = 0\n",
    "for i in sort2:\n",
    "    number = neg_word_counts_dict.get(i)\n",
    "    neg_tokens += number\n",
    "    \n",
    "print(neg_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: calculate word probability (version 1.0)\n",
    "\n",
    "Create a function `word_prob` that takes three arguments: a word, a counter, and a sum. It should return the probability of the word estimated from that counter. Assume that the sum is accurate, you don't need to check for errors.\n",
    "\n",
    "Use this function to print the probability of the words \"delicious\", \"manager\", \"edgy\", and \"vile\" in both sub-collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012819741921518166\n",
      "5.539815445005461e-05\n",
      "0.00016836434043269636\n",
      "0.001044650912486744\n",
      "4.810409726648467e-06\n",
      "0\n",
      "0\n",
      "7.914022064293515e-06\n"
     ]
    }
   ],
   "source": [
    "def word_prob(word, counter, sum):\n",
    "    counter_dict = dict(counter)\n",
    "    if counter_dict.get(word) == None:\n",
    "        prob = 0\n",
    "        return prob\n",
    "    occur = counter_dict.get(word)\n",
    "    prob = occur/sum\n",
    "    \n",
    "    return prob\n",
    "\n",
    "print(word_prob(\"delicious\", pos_word_counts, pos_tokens))\n",
    "print(word_prob(\"delicious\", neg_word_counts, neg_tokens))\n",
    "print(word_prob(\"manager\", pos_word_counts, pos_tokens))\n",
    "print(word_prob(\"manager\", neg_word_counts, neg_tokens))\n",
    "print(word_prob(\"edgy\", pos_word_counts, pos_tokens))\n",
    "print(word_prob(\"edgy\", neg_word_counts, neg_tokens))\n",
    "print(word_prob(\"vile\", pos_word_counts, pos_tokens))\n",
    "print(word_prob(\"vile\", neg_word_counts, neg_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: probability of a sequence (version 1.0)\n",
    "\n",
    "Now create a function `review_prob` that takes a string containing multiple words (for example \"the food was delicious\"), a counter, and a sum. It should use the same regular expression method you used when reading the files earlier to break this string into tokens, and then use `word_prob` to calculate the probability of each of those word tokens. It should then return the product of those probabilities.\n",
    "\n",
    "Print the probability of \"I loved the carnitas\", \"but then the manager came out and told us\", and \"the ambience was edgy but the food was vile\" according to both sub-collections. What do you notice about these six probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2250003720826804e-11\n",
      "7.596215739715786e-13\n",
      "9.500532817312996e-25\n",
      "2.2807647439322206e-22\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def review_prob(words, counter, sum):\n",
    "    eachword = words.split(' ')\n",
    "    prob = 1\n",
    "    for i in eachword:\n",
    "        prob *= word_prob(i, counter, sum)\n",
    "        \n",
    "    return prob\n",
    "\n",
    "print(review_prob(\"I loved the carnitas\", pos_word_counts, pos_tokens))\n",
    "print(review_prob(\"I loved the carnitas\", neg_word_counts, neg_tokens))\n",
    "print(review_prob(\"but then the manager came out and told us\", pos_word_counts, pos_tokens))\n",
    "print(review_prob(\"but then the manager came out and told us\", neg_word_counts, neg_tokens))\n",
    "print(review_prob(\"the ambience was edgy but the food was vile\", pos_word_counts, pos_tokens))\n",
    "print(review_prob(\"the ambience was edgy but the food was vile\", neg_word_counts, neg_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations about the six probabilities here:\n",
    "\n",
    "The probabilities are very small, which makes sense because these are random sentences that don't have much to do with the content of reviews, so the likelihood of them popping up is very small. Additionally, it is less likely for a specific order of words to appear over singular words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: calculate word probability (version 2.0)\n",
    "\n",
    "Instead of multiplying probabilities, we can also add *log* probabilities. Create a function `word_log_prob` that calculates the log probability of a word, and a function `review_log_prob` that calculates the sum of the log probabilities of the words in a string. These should take the same arguments as the previous functions.\n",
    "\n",
    "Print the log probabilities of the same example words and sentences from the previous problems. Explain any errors that occur in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.659354051613109\n",
      "-25.125494875196893\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def word_log_prob(word, counter, sum):\n",
    "    prob = word_prob(word, counter, sum)\n",
    "    log = math.log(prob)\n",
    "    return log\n",
    "    \n",
    "def review_log_prob(words, counter, sum):\n",
    "    eachword = words.split(' ')\n",
    "    prob = 0\n",
    "    for i in eachword:\n",
    "        prob += math.log(word_prob(i, counter, sum))\n",
    "    return prob\n",
    "\n",
    "print(word_log_prob(\"delicious\", pos_word_counts, pos_tokens))\n",
    "print(review_log_prob(\"I loved the carnitas\", pos_word_counts, pos_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a word type never occurs in our negative reviews, it will have probability zero. But we don't want to rule out the possibility that any future negative review could include that word type. We need to a way to give non-zero probability in both positive and negative polarities to a word that we have only seen in one. A simple way to do this is to add 1 to the count when we calculate word probability, as long as the word has appeared in at least one sub-collection (words we have never seen in either sub-collection will still have probability zero).\n",
    "\n",
    "This change avoids log-zero errors, but it violates the laws of probability. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here: Probability is a number between 0 and 1, so adding 1 even once would make the probability of something happening at least 100%, much likely greater. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Collection statistics\n",
    "\n",
    "Create a `Counter` called `both_counts` by adding the two negative and positive counters together (just use +, Counters are awesome). Create a new variable `both_tokens` to represent the total number of tokens in the collection. Create a variable `vocabulary_size` whose value is the total number of distinct word types in the collection. Print the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542123\n",
      "24182\n"
     ]
    }
   ],
   "source": [
    "both_counts = pos_word_counts + neg_word_counts\n",
    "# print(both_counts)\n",
    "both_tokens = pos_tokens + neg_tokens\n",
    "print(both_tokens)   \n",
    "vocabulary_size = len(both_counts)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11: Calculate word probability (version 3.0)\n",
    "\n",
    "Now create a function `smoothed_word_log_prob` that takes the same arguments as `word_prob` (word, counter, sum of the counter), but adds 1 to the count for the word (don't modify the counter, just add 1 in your function). Previously we divided the word count by the sum of all the counts in the counter, which guaranteed that the sum of the probability of all word types was 1.0. Now that we are adding 1 to each word, what should the denominator be so that this new probability distribution will sum to 1.0?\n",
    "\n",
    "Use this function to print the log probability of the words \"delicious\", \"manager\", \"edgy\", and \"vile\" in both sub-collections. (These function calls should have the exact same arguments as the previous blocks.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.659351646405353\n",
      "-8.689377828521838\n"
     ]
    }
   ],
   "source": [
    "def smoothed_word_log_prob(word, counter, sum):\n",
    "    dict_counter = dict(counter)\n",
    "    count = 0\n",
    "    for i in dict_counter:\n",
    "        if i == word:\n",
    "            count = dict_counter[i]\n",
    "            count = count + 1\n",
    "            newsum = sum - 1\n",
    "        \n",
    "    return word_log_prob(word, counter, newsum)\n",
    "        \n",
    "print(smoothed_word_log_prob(\"delicious\", pos_word_counts, pos_tokens))\n",
    "print(smoothed_word_log_prob(\"manager\", pos_word_counts, pos_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12: Test your classifier!\n",
    "\n",
    "Now let's put it all together. Given a review, we want to know whether that review is more likely to be positive or negative. To answer this question we will calculate the log of the ratio between $P(positive | words\\ in\\ review)$ and $P(negative | words\\ in\\ review)$. This ratio is simpler than the two individual. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate this ratio for the review \"the ambience was edgy but the food was disgusting\". Use the probability that a review is positive or negative that you calculated earlier as the prior probabilities $P(positive)$ and $P(negative)$, but this time use the log of those probabilities. Print the resulting log probability ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How should you interpret the log probability ratio?\n",
    "* Which category is more likely?\n",
    "* Does the prior probability matter?\n",
    "* Suggest a prior probability that would change our decision, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
